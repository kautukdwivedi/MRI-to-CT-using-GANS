{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ateZDPWb0PlZ"
      },
      "source": [
        "**MRI to CT conversion using paired and unpaired data-set**\n",
        "\n",
        "For this project we are using gans i.e. Generative Adversial Network</br>\n",
        "To implement our model we are using pytorch as neural network library.<br/>These are all set of libraries / dependencies that we need to import:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "51E-0HPcpFpj",
        "outputId": "bf2c31fd-1963-4f64-9f0a-65d9a6353424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.6)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65174 sha256=afba2568ea71f8bbb36e73e77ec23730aadaf6af3eb44260142dafb0900f9b21\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations==0.4.6\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensor\n",
        "from PIL import Image\n",
        "import os, random, copy, os, sys, torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from albumentations.pytorch import ToTensor\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlTveAwp3D19"
      },
      "source": [
        "**Discriminator Block**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-D2ksxrWp8_x"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=True, padding_mode=\"reflect\"),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                features[0],\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layers.append(Block(in_channels, feature, stride=1 if feature==features[-1] else 2))\n",
        "            in_channels = feature\n",
        "        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        return torch.sigmoid(self.model(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd-PuNSz3WtM"
      },
      "source": [
        "**Generator Block**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EKRnsBNLqDAm"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n",
        "            if down\n",
        "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True) if use_act else nn.Identity()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            ConvBlock(channels, channels, kernel_size=3, padding=1),\n",
        "            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, img_channels, num_features = 64, num_residuals=9):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
        "            # nn.InstanceNorm2d(num_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.down_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n",
        "                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n",
        "            ]\n",
        "        )\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n",
        "        )\n",
        "        self.up_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "                ConvBlock(num_features*2, num_features*1, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.last = nn.Conv2d(num_features*1, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        for layer in self.down_blocks:\n",
        "            x = layer(x)\n",
        "        x = self.res_blocks(x)\n",
        "        for layer in self.up_blocks:\n",
        "            x = layer(x)\n",
        "        return torch.tanh(self.last(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vMNJirX4Vdk"
      },
      "source": [
        "**Class for Data Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F-z2t2CvHkbu"
      },
      "outputs": [],
      "source": [
        "class MriCtDataset(Dataset):\n",
        "    def __init__(self, root_ct, root_mri, transform=None):\n",
        "        self.root_ct = root_ct\n",
        "        self.root_mri = root_mri\n",
        "        self.transform = transform\n",
        "\n",
        "        self.ct_images = os.listdir(root_ct)\n",
        "        self.mri_images = os.listdir(root_mri)\n",
        "        self.lengtM_dataset = len(self.mri_images) # 1000, 1500\n",
        "        self.ct_images.sort()\n",
        "        self.mri_images.sort()\n",
        "        self.ct_len = len(self.ct_images)\n",
        "        self.mri_len = len(self.mri_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.lengtM_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ct_img = self.ct_images[index % self.ct_len]\n",
        "        mri_img = self.mri_images[index % self.mri_len]\n",
        "\n",
        "        ct_path = os.path.join(self.root_ct, ct_img)\n",
        "        mri_path = os.path.join(self.root_mri, mri_img)\n",
        "\n",
        "        ct_img = np.array(Image.open(ct_path).convert(\"RGB\"))\n",
        "        mri_img = np.array(Image.open(mri_path).convert(\"RGB\"))\n",
        "\n",
        "        if self.transform:\n",
        "            augmentations = self.transform(image=ct_img, image0=mri_img)\n",
        "            ct_img = augmentations[\"image\"]\n",
        "            mri_img = augmentations[\"image0\"]\n",
        "            #print(\"inside L\" + str(index) + \"ct Return -> \" + ct_path + \"mri Return -> \" + mri_path)\n",
        "            \n",
        "        return ct_img, mri_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TR3Wp_V5DTo"
      },
      "source": [
        "**All constants values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-lXtzFNgqQTe"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "PUP_DIR = \"/content/drive/MyDrive/data/\"\n",
        "CYCLE_DIR = \"/content/drive/MyDrive/data_c/\"\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "LAMBDA_IDENTITY = 0.0\n",
        "LAMBDA_CYCLE = 10\n",
        "LAMBDA_PAIRED = 30\n",
        "NUM_WORKERS = 4\n",
        "NUM_EPOCHS = 1\n",
        "LOAD_MODEL = True\n",
        "SAVE_MODEL = False\n",
        "CHECKPOINT_GEN_M_PUP = PUP_DIR + \"saved_checkp/genh.pth.tar\"\n",
        "CHECKPOINT_GEN_C_PUP = PUP_DIR + \"saved_checkp/genz.pth.tar\"\n",
        "CHECKPOINT_CRITIC_M_PUP = PUP_DIR + \"saved_checkp/critich.pth.tar\"\n",
        "CHECKPOINT_CRITIC_C_PUP = PUP_DIR + \"saved_checkp/criticz.pth.tar\"\n",
        "CHECKPOINT_GEN_M_CYCLE = CYCLE_DIR + \"saved_checkp/genh.pth.tar\"\n",
        "CHECKPOINT_GEN_C_CYCLE = CYCLE_DIR + \"saved_checkp/genz.pth.tar\"\n",
        "CHECKPOINT_CRITIC_M_CYCLE = CYCLE_DIR + \"saved_checkp/critich.pth.tar\"\n",
        "CHECKPOINT_CRITIC_C_CYCLE = CYCLE_DIR + \"saved_checkp/criticz.pth.tar\"\n",
        "\n",
        "transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensor(),\n",
        "     ],\n",
        "    additional_targets={\"image0\": \"image\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7IvoJSS56GC"
      },
      "source": [
        "**To save and load checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KVsYkC3gqTYx"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxh1kqZs6FqN"
      },
      "source": [
        "**Traning function for PUP Gans**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-2I7oLc0qfKP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_fn(disc_M, disc_C, gen_C, gen_M, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler, nature):\n",
        "    M_reals = 0\n",
        "    M_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (ct, mri) in enumerate(loop):\n",
        "        ct = ct.to(DEVICE)\n",
        "        mri = mri.to(DEVICE)\n",
        "\n",
        "        # Train Discriminators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_mri = gen_M(ct)\n",
        "            D_M_real = disc_M(mri)\n",
        "            D_M_fake = disc_M(fake_mri.detach())\n",
        "            M_reals += D_M_real.mean().item()\n",
        "            M_fakes += D_M_fake.mean().item()\n",
        "            D_M_real_loss = mse(D_M_real, torch.ones_like(D_M_real))\n",
        "            D_M_fake_loss = mse(D_M_fake, torch.zeros_like(D_M_fake))\n",
        "            D_M_loss = D_M_real_loss + D_M_fake_loss\n",
        "\n",
        "            fake_ct = gen_C(mri)\n",
        "            D_C_real = disc_C(ct)\n",
        "            D_C_fake = disc_C(fake_ct.detach())\n",
        "            D_C_real_loss = mse(D_C_real, torch.ones_like(D_C_real))\n",
        "            D_C_fake_loss = mse(D_C_fake, torch.zeros_like(D_C_fake))\n",
        "            D_C_loss = D_C_real_loss + D_C_fake_loss\n",
        "\n",
        "            # put it togethor\n",
        "            D_loss = (D_M_loss + D_C_loss)/2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train Generators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            D_M_fake = disc_M(fake_mri)\n",
        "            D_C_fake = disc_C(fake_ct)\n",
        "            loss_G_M = mse(D_M_fake, torch.ones_like(D_M_fake))\n",
        "            loss_G_C = mse(D_C_fake, torch.ones_like(D_C_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_ct = gen_C(fake_mri)\n",
        "            cycle_mri = gen_M(fake_ct)\n",
        "            cycle_ct_loss = l1(ct, cycle_ct)\n",
        "            cycle_mri_loss = l1(mri, cycle_mri)\n",
        "\n",
        "            # identity loss (remove these for efficiency if you set lambda_identity=0)\n",
        "            identity_ct = gen_C(ct)\n",
        "            identity_mri = gen_M(mri)\n",
        "            identity_ct_loss = l1(ct, identity_ct)\n",
        "            identity_mri_loss = l1(mri, identity_mri)\n",
        "            \n",
        "            # add all togethor\n",
        "            G_loss = (\n",
        "                loss_G_C\n",
        "                + loss_G_M\n",
        "                + cycle_ct_loss * LAMBDA_CYCLE\n",
        "                + cycle_mri_loss * LAMBDA_CYCLE\n",
        "                + identity_mri_loss * LAMBDA_IDENTITY\n",
        "                + identity_ct_loss * LAMBDA_IDENTITY\n",
        "            )\n",
        "\n",
        "            # paired loss\n",
        "            if(nature == True):\n",
        "                P_C = l1(ct,fake_ct)\n",
        "                P_M = l1(mri,fake_mri)\n",
        "\n",
        "                P_loss = P_C + P_M\n",
        "                G_loss = G_loss + (P_loss * LAMBDA_PAIRED)                     \n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        if idx % 400 == 0 and nature == False:\n",
        "            save_image(mri*0.5+0.5, PUP_DIR + f\"saved_image/MR_UPR{idx}.png\")\n",
        "            save_image(ct*0.5+0.5, PUP_DIR + f\"saved_image/CT_UPR{idx}.png\")\n",
        "            save_image(fake_mri*0.5+0.5, PUP_DIR + f\"saved_image/MR_UP{idx}.png\")\n",
        "            save_image(fake_ct*0.5+0.5, PUP_DIR + f\"saved_image/CT_UP{idx}.png\")\n",
        "\n",
        "        if nature == True:\n",
        "            save_image(mri*0.5+0.5, PUP_DIR + f\"saved_image/MR_PR{idx}.png\")\n",
        "            save_image(ct*0.5+0.5, PUP_DIR + f\"saved_image/CT_PR{idx}.png\")\n",
        "            save_image(fake_mri*0.5+0.5, PUP_DIR + f\"saved_image/MR_P{idx}.png\")\n",
        "            save_image(fake_ct*0.5+0.5, PUP_DIR + f\"saved_image/CT_P{idx}.png\")\n",
        "\n",
        "        loop.set_postfix(M_real=M_reals/(idx+1), M_fake=M_fakes/(idx+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-Vsk3X279i7"
      },
      "source": [
        "**Training function for cycle gans**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OP90s9OJ8CLh"
      },
      "outputs": [],
      "source": [
        "def train_fn_cycle(disc_M, disc_C, gen_C, gen_M, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler):\n",
        "    M_reals = 0\n",
        "    M_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (ct, mri) in enumerate(loop):\n",
        "        ct = ct.to(DEVICE)\n",
        "        mri = mri.to(DEVICE)\n",
        "\n",
        "        # Train Discriminators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_mri = gen_M(ct)\n",
        "            D_M_real = disc_M(mri)\n",
        "            D_M_fake = disc_M(fake_mri.detach())\n",
        "            M_reals += D_M_real.mean().item()\n",
        "            M_fakes += D_M_fake.mean().item()\n",
        "            D_M_real_loss = mse(D_M_real, torch.ones_like(D_M_real))\n",
        "            D_M_fake_loss = mse(D_M_fake, torch.zeros_like(D_M_fake))\n",
        "            D_M_loss = D_M_real_loss + D_M_fake_loss\n",
        "\n",
        "            fake_ct = gen_C(mri)\n",
        "            D_C_real = disc_C(ct)\n",
        "            D_C_fake = disc_C(fake_ct.detach())\n",
        "            D_C_real_loss = mse(D_C_real, torch.ones_like(D_C_real))\n",
        "            D_C_fake_loss = mse(D_C_fake, torch.zeros_like(D_C_fake))\n",
        "            D_C_loss = D_C_real_loss + D_C_fake_loss\n",
        "\n",
        "            # put it togethor\n",
        "            D_loss = (D_M_loss + D_C_loss)/2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train Generators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            D_M_fake = disc_M(fake_mri)\n",
        "            D_C_fake = disc_C(fake_ct)\n",
        "            loss_G_M = mse(D_M_fake, torch.ones_like(D_M_fake))\n",
        "            loss_G_C = mse(D_C_fake, torch.ones_like(D_C_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_ct = gen_C(fake_mri)\n",
        "            cycle_mri = gen_M(fake_ct)\n",
        "            cycle_ct_loss = l1(ct, cycle_ct)\n",
        "            cycle_mri_loss = l1(mri, cycle_mri)\n",
        "\n",
        "            # identity loss (remove these for efficiency if you set lambda_identity=0)\n",
        "            identity_ct = gen_C(ct)\n",
        "            identity_mri = gen_M(mri)\n",
        "            identity_ct_loss = l1(ct, identity_ct)\n",
        "            identity_mri_loss = l1(mri, identity_mri)\n",
        "            \n",
        "            # add all togethor\n",
        "            G_loss = (\n",
        "                loss_G_C\n",
        "                + loss_G_M\n",
        "                + cycle_ct_loss * LAMBDA_CYCLE\n",
        "                + cycle_mri_loss * LAMBDA_CYCLE\n",
        "                + identity_mri_loss * LAMBDA_IDENTITY\n",
        "                + identity_ct_loss * LAMBDA_IDENTITY\n",
        "            )                \n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        if idx % 200 == 0:\n",
        "            save_image(mri*0.5+0.5, PUP_DIR + f\"saved_image/MR_UPR{idx}.png\")\n",
        "            save_image(ct*0.5+0.5, PUP_DIR + f\"saved_image/CT_UPR{idx}.png\")\n",
        "            save_image(fake_mri*0.5+0.5, PUP_DIR + f\"saved_image/MR_UP{idx}.png\")\n",
        "            save_image(fake_ct*0.5+0.5, PUP_DIR + f\"saved_image/CT_UP{idx}.png\")\n",
        "\n",
        "        loop.set_postfix(M_real=M_reals/(idx+1), M_fake=M_fakes/(idx+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlHIqWb38RrS"
      },
      "source": [
        "**Test Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9nMeTPnR8TdF"
      },
      "outputs": [],
      "source": [
        "def test_fn(gen_C, gen_M, loader, l1):\n",
        "\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for idx, (ct, mri) in enumerate(loop):\n",
        "        ct = ct.to(DEVICE)\n",
        "        mri = mri.to(DEVICE)\n",
        "        \n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_ct = gen_C(mri)\n",
        "        save_image(mri*0.5+0.5, PUP_DIR + f\"saved_image/{idx}_MR_Real.png\")\n",
        "        save_image(ct*0.5+0.5, PUP_DIR + f\"saved_image/{idx}_CT_Real.png\")\n",
        "        save_image(fake_ct*0.5+0.5, PUP_DIR + f\"saved_image/{idx}_CT_Fake.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEABY8o_8iWX"
      },
      "source": [
        "**Main function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAFtMdq38lAR"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    disc_M = Discriminator(in_channels=3).to(DEVICE)\n",
        "    disc_C = Discriminator(in_channels=3).to(DEVICE)\n",
        "    gen_C = Generator(img_channels=3, num_residuals=9).to(DEVICE)\n",
        "    gen_M = Generator(img_channels=3, num_residuals=9).to(DEVICE)\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_M.parameters()) + list(disc_C.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_C.parameters()) + list(gen_M.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_M_PUP, gen_M, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_C_PUP, gen_C, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_M_PUP, disc_M, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_C_PUP, disc_C, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "    #datasetUP = MriCtDataset(root_mri=CYCLE_DIR + \"MRI\", root_ct= CYCLE_DIR + \"CT\", transform=transforms)\n",
        "    #datasetP = MriCtDataset(root_mri=CYCLE_DIR + \"MRI-Paired\", root_ct= CYCLE_DIR + \"CT-Paired\", transform=transforms)\n",
        "    datasetP = MriCtDataset(root_mri=CYCLE_DIR + \"MRI-Select\", root_ct= CYCLE_DIR + \"CT-Select\", transform=transforms)\n",
        "\n",
        "    \n",
        "    '''loaderUP = DataLoader(\n",
        "        datasetUP,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True\n",
        "    )'''\n",
        "    loaderP = DataLoader(\n",
        "        datasetP,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        #train_fn_cycle(disc_M, disc_C, gen_C, gen_M, loaderUP, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler)\n",
        "        train_fn(disc_M, disc_C, gen_C, gen_M, loaderP, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler, True)\n",
        "        #print(epoch)\n",
        "\n",
        "        if SAVE_MODEL:\n",
        "            save_checkpoint(gen_M, opt_gen, filename=CHECKPOINT_GEN_M_PUP)\n",
        "            save_checkpoint(gen_C, opt_gen, filename=CHECKPOINT_GEN_C_PUP)\n",
        "            save_checkpoint(disc_M, opt_disc, filename=CHECKPOINT_CRITIC_M_PUP)\n",
        "            save_checkpoint(disc_C, opt_disc, filename=CHECKPOINT_CRITIC_C_PUP)\n",
        "\n",
        "    #test_fn(gen_C, gen_M, loaderP, L1)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "final_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}